values_from = c(mean, median, count, min, max)) %>%
arrange (standard_app_type) %>%
mutate (change_med = median_2021 - median_2020)
#natl_averages2 <- natl_avg_lic_type
#What about for new licenses only, grouped into LPN + RN?
natl_avg_lic_type <- valid_data3 %>%
mutate (year = if_else (str_detect(year, "^Pending"), "Pending", year)) %>%
filter (!(standard_app_type %in% c("Reinstatement", "Renewal", "Exam-retest"))) %>%
group_by (lic_type, year) %>%
summarize (mean = round(mean(process_time2)),
median = median (process_time2),
count = n(),
count_over30days = sum(process_time2 > 30),
pct_over30days = count_over30days/count,
count_over60days = sum(process_time2 > 60),
pct_over60days = count_over60days/count,
count_over90days = sum(process_time2 > 90),
pct_over90days = count_over90days/count,
count_over120days = sum(process_time2 > 120),
pct_over120days = count_over120days/count,
count_over180days = sum(process_time2 > 180),
pct_over180days = count_over180days/count,
count_over1year = sum(process_time2 > 365),
pct_over1year = count_over1year/count) %>%
filter (year != "2019")
#Nationally, RN licenses are taking 5 days longer and LPNs are taking 6 days longer than last year.
natl_comparison2 <- natl_avg_lic_type %>%
#filter (lic_type %in% c("LPN", "RN")) %>%
filter (year %in% c("2020", "2021")) %>%
pivot_wider (id_cols = c(lic_type),
names_from = year,
values_from = c(mean, median, count)) %>%
#arrange (standard_app_type) %>%
mutate (change_med = median_2021 - median_2020)
#Percent of new licenses issued that took longer than a month increased from 78% in 2020 to 80% in 2021.
#Percent of new licenses issued that took longer than 2 months increased from 53% in 2020 to 57% in 2021.
#Percent of new licenses issued that took longer than 3 months increased from 31% in 2020 to 35% in 2021.
#What about for all new RN/LPN licenses, grouping exam, endorsement, other and unknown together?
#app_types: Unknown is mostly CT/VA, which didn't specify application type
natl_averages_combined <- valid_data3 %>%
mutate (year = if_else (str_detect(year, "^Pending"), "Pending", year)) %>%
filter (lic_type %in% c("LPN", "RN")) %>%
filter (!(standard_app_type %in% c("Reinstatement", "Renewal", "Exam-retest"))) %>%
group_by (year) %>%
summarize (mean = round(mean(process_time2)),
median = median (process_time2),
count = n(),
count_over30days = sum(process_time2 > 30),
pct_over30days = count_over30days/count,
count_over60days = sum(process_time2 > 60),
pct_over60days = count_over60days/count,
count_over90days = sum(process_time2 > 90),
pct_over90days = count_over90days/count,
count_over120days = sum(process_time2 > 120),
pct_over120days = count_over120days/count,
count_over180days = sum(process_time2 > 180),
pct_over180days = count_over180days/count,
count_over1year = sum(process_time2 > 365),
pct_over1year = count_over1year/count) %>%
filter (year != "2019")
#Group by application type only
#app_types: Unknown is mostly CT/VA, which didn't specify application type
natl_avg_app_type_only <- valid_data3 %>%
mutate (year = if_else (str_detect(year, "^Pending"), "Pending", year)) %>%
filter (lic_type %in% c("LPN", "RN")) %>%
filter (!(standard_app_type %in% c("Reinstatement", "Renewal", "Exam-retest"))) %>%
mutate (lic_type = "LPN+RN") %>%
group_by (lic_type, standard_app_type, year) %>%
summarize (mean = round(mean(process_time2)),
median = median (process_time2),
count = n(),
count_over30days = sum(process_time2 > 30),
pct_over30days = count_over30days/count,
count_over60days = sum(process_time2 > 60),
pct_over60days = count_over60days/count,
count_over90days = sum(process_time2 > 90),
pct_over90days = count_over90days/count,
count_over120days = sum(process_time2 > 120),
pct_over120days = count_over120days/count,
count_over180days = sum(process_time2 > 180),
pct_over180days = count_over180days/count,
count_over1year = sum(process_time2 > 365),
pct_over1year = count_over1year/count) %>%
filter (year != "2019")
#Write summary files
write_csv (natl_averages, "../output/natl_averages_by_app_lic_type.csv")
write_csv (natl_avg_lic_type, "../output/natl_averages_lic_type_only.csv")
write_csv (natl_avg_app_type_only, "../output/natl_averages_app_type_only.csv")
write_csv (natl_averages_combined, "../output/natl_averages_combined.csv")
end_time <- Sys.time()
paste ("Processing time lasted", (end_time-start_time))
View(valid_data3)
valid_data3 %>%
count (app_type)
valid_data3 %>%
count (standard_app_type)
View(fl_state)
valid_data21 %>%
count (standard_app_type)
valid_data21_issued %>%
count (standard_app_type)
valid_data21_issued %>%
count (lic_type, standard_app_type)
valid_data21_issued %>%
count (lic_type, standard_app_type)
valid_data21_issued %>%
count (lic_type, standard_app_type) %>%
print (1e3)
valid_data21_issued %>%
count (standard_app_type) %>%
print (1e3)
View(state_avg_lic_type_only)
#How many of each application type were issued in 2021?
valid_data3 %>%
filter (year %in% c("2020", "2021")|str_detect(year, "^Pending")) %>%
count (standard_app_type) %>%
print (1e3)
#Where do "Other" applications come from?
valid_data3 %>%
filter (standard_app_type=="Other") %>%
count (data_state) %>%
arrange (desc(n))
#Where do "Other" applications come from? mostly
valid_data3 %>%
filter (standard_app_type=="Other") %>%
count (data_state, app_type) %>%
arrange (desc(n))
valid_data3 %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, app_type) %>%
arrange (desc(n))
valid_data3 %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, lic_type) %>%
arrange (desc(n))
valid_data3 %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, lic_type, app_type) %>%
arrange (desc(n))
View(mi_state)
valid_data3 %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, lic_type, app_type, year) %>%
arrange (desc(n))
valid_data3 %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, lic_type, app_type) %>%
arrange (desc(n))
valid_data3 %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, app_type) %>%
arrange (desc(n))
valid_data3 %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, lic_type, app_type) %>%
arrange (desc(n))
valid_data3 %>%
filter (standard_app_type=="Other") %>%
count (data_state, app_type) %>%
arrange (desc(n)) %>%
adorn_totals()
valid_data3 %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, lic_type, app_type) %>%
arrange (desc(n)) %>%
adorn_totals()
valid_data3 %>%
filter (year %in% c("2021", "2020") | str_detect(year, "^Pending")) %>%
filter (standard_app_type=="Other") %>%
count (data_state, app_type) %>%
arrange (desc(n)) %>%
adorn_totals()
valid_data3 %>%
filter (year %in% c("2021", "2020") | str_detect(year, "^Pending")) %>%
filter (standard_app_type=="Unknown") %>%
count (data_state, lic_type, app_type) %>%
arrange (desc(n)) %>%
adorn_totals()
fl_state %>%
count (lic_type, app_type)
#How many of each application type were issued in 2021?
valid_data21_issued %>%
count (standard_app_type) %>%
print (1e3)
#Load libraries
library(tidyverse)
library(janitor)
library(lubridate)
#Load libraries
library(tidyverse)
library(janitor)
library(lubridate)
hospital <- data.table::fread("https://healthdata.gov/api/views/g62h-syeh/rows.csv?accessType=DOWNLOAD") %>%
mutate (date =ymd(date)) %>%
collect()
hospital2 <- hospital %>%
group_by (date, state) %>%
select (date, state, critical_staffing_shortage_today_yes, critical_staffing_shortage_today_no, critical_staffing_shortage_today_not_reported) %>%
mutate (total = critical_staffing_shortage_today_yes + critical_staffing_shortage_today_no + critical_staffing_shortage_today_not_reported,
pct_yes = critical_staffing_shortage_today_yes / (critical_staffing_shortage_today_yes + critical_staffing_shortage_today_no),
pct_reporting = (critical_staffing_shortage_today_yes + critical_staffing_shortage_today_no) / total)
hospital2 %>%
filter (state == "TX") %>%
#filter (date > as.Date("2021-12-31")) %>%
ggplot (aes(x = date,
y = pct_yes,
#fill = state
)) +
geom_line()
#Check how states are doing
hospital2 %>%
filter (date == (Sys.Date()-5)) %>%
arrange (desc(pct_yes)) %>%
View
hospital3 <- hospital %>%
group_by (date) %>%
select (date, state, critical_staffing_shortage_today_yes, critical_staffing_shortage_today_no, critical_staffing_shortage_today_not_reported) %>%
summarize (total = sum(critical_staffing_shortage_today_yes) + sum(critical_staffing_shortage_today_no) + sum(critical_staffing_shortage_today_not_reported),
pct_yes = sum(critical_staffing_shortage_today_yes) / (sum(critical_staffing_shortage_today_yes) + sum(critical_staffing_shortage_today_no)),
pct_reporting = (sum(critical_staffing_shortage_today_yes) + sum(critical_staffing_shortage_today_no)) / total) %>%
#arrange (desc(date))%>%
arrange (date) %>%
mutate (#days_low_vax = RcppRoll::roll_sum(dplyr::lag(low_vax),14, fill=NA, align="right"),
#days_low_st_vax = RcppRoll::roll_sum(dplyr::lag(low_st_vax),14, fill=NA, align="right"),
roll_avg = zoo::rollmean(pct_yes, k = 7, fill = NA, align = "right")* 100)
hospital3 %>%
ggplot (aes(x = date,
y = pct_yes,
#fill = state
)) +
geom_line()
hospital4 <- hospital %>%
#group_by (date, state) %>% #USE THIS TO GROUP BY DATE AND STATE INSTEAD OF NATIONAL RATE
group_by (date) %>%
select (date, state, critical_staffing_shortage_anticipated_within_week_yes, critical_staffing_shortage_anticipated_within_week_no, critical_staffing_shortage_anticipated_within_week_not_reported) %>%
#sum up three possible responses
summarize (tot_report =  sum(critical_staffing_shortage_anticipated_within_week_yes) +  sum(critical_staffing_shortage_anticipated_within_week_no),
total = sum(critical_staffing_shortage_anticipated_within_week_yes) + sum(critical_staffing_shortage_anticipated_within_week_no) + sum(critical_staffing_shortage_anticipated_within_week_not_reported),
#Of those that responded, calculate percent responding yes
pct_yes = sum(critical_staffing_shortage_anticipated_within_week_yes) / (sum(critical_staffing_shortage_anticipated_within_week_yes) + sum(critical_staffing_shortage_anticipated_within_week_no)),
#Calculate percent that responded
pct_reporting = (sum(critical_staffing_shortage_anticipated_within_week_yes) + sum(critical_staffing_shortage_anticipated_within_week_no)) / total) %>%
arrange (desc(date)) %>%
filter (date > as.Date("2020-07-31"))
hospital4a <- hospital4 %>%
arrange (date) %>%
mutate (#days_low_vax = RcppRoll::roll_sum(dplyr::lag(low_vax),14, fill=NA, align="right"),
#days_low_st_vax = RcppRoll::roll_sum(dplyr::lag(low_st_vax),14, fill=NA, align="right"),
x7_day_rolling_reporting = zoo::rollmean(tot_report, k = 7, fill = NA, align = "right"),
x7_day_rolling_avg_pct_hospitals_anticipating_shortage = zoo::rollmean(pct_yes, k = 7, fill = NA, align = "right")* 100,
#Don't think this is actually correct -- should be weighted
x7_day_rolling_avg_pct_hospitals_reporting = zoo::rollmean(pct_reporting, k = 7, fill = NA, align = "right")* 100,
x7day_correct_avg = zoo::rollsum(tot_report, k = 7, fill = NA, align = "right") / zoo::rollsum(total, k = 7, fill = NA, align = "right") * 100) %>%
rename (pct_hospitals_anticipating_shortage = pct_yes,
pct_hospitals_reporting = pct_reporting) %>%
arrange (desc(date)) #rearrange, most recent first
hospital4a %>%
filter (date > as.Date("2020-07-31")) %>%
ggplot (aes(x = date)) +
geom_line(aes(y = x7_day_rolling_avg_pct_hospitals_anticipating_shortage), color = "darkred") +
#    geom_line(aes(y = x7_day_rolling_avg_pct_hospitals_reporting), color="steelblue", linetype="twodash") +
labs(x="Date",
y="% of hospitals (7-day rolling average)",
title="Hospitals anticipating critical staffing shortages within a week",
#subtitle="",
#fill="95% CI for trendline",
caption="Source: U.S. Department of Health & Human Services") +
scale_x_date(#limits = c(as.Date("2006-12-31"), as.Date("2014-09-30")),
breaks = seq(as.Date("2020-08-01"), (Sys.Date()+weeks(2)), "month"),
date_labels = "%b %Y") +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
scale_y_continuous(limits = c(0, 30),
breaks = seq(0, 30, by = 5),
labels = paste0(seq(0, 30, by = 5), "%")) +
#geom_vline(xintercept = ) +
# Shade area under y_lim
#geom_rect(aes(xmin = as.Date("2021-09-01"), xmax = as.Date("2021-10-01"), ymin = 0, ymax = Inf),
annotate("rect", xmin=as.Date("2020-11-01"), xmax=as.Date("2021-02-01"), ymin=0, ymax=Inf, alpha=0.2, fill="red") +
annotate(geom="text", x=as.Date("2020-12-15"), y=1, label="1st winter wave", size =3) +
annotate("rect", xmin=as.Date("2021-08-01"), xmax=as.Date("2021-10-01"), ymin=0, ymax=Inf, alpha=0.2, fill="red") +
annotate(geom="text", x=as.Date("2021-09-01"), y=1, label="Delta wave", size =3) +
annotate("rect", xmin=as.Date("2021-12-15"), xmax=as.Date("2022-02-01"), ymin=0, ymax=Inf, alpha=0.2, fill="red") +
annotate(geom="text", x=as.Date("2022-01-08"), y=2, label="Omicron\nwave", size =3)
#write_csv(hospital4a, "hhs_hospitals_anticipating_critical_staffing_shortages.csv")
hospital5 <- hospital %>%
group_by (date, state) %>% #USE THIS TO GROUP BY DATE AND STATE INSTEAD OF NATIONAL RATE
select (date, state, critical_staffing_shortage_anticipated_within_week_yes, critical_staffing_shortage_anticipated_within_week_no, critical_staffing_shortage_anticipated_within_week_not_reported) %>%
#sum up three possible responses
summarize (tot_report =  sum(critical_staffing_shortage_anticipated_within_week_yes) +  sum(critical_staffing_shortage_anticipated_within_week_no),
total = sum(critical_staffing_shortage_anticipated_within_week_yes) + sum(critical_staffing_shortage_anticipated_within_week_no) + sum(critical_staffing_shortage_anticipated_within_week_not_reported),
#Of those that responded, calculate percent responding yes
pct_yes = sum(critical_staffing_shortage_anticipated_within_week_yes) / (sum(critical_staffing_shortage_anticipated_within_week_yes) + sum(critical_staffing_shortage_anticipated_within_week_no)),
#Calculate percent that responded
pct_reporting = (sum(critical_staffing_shortage_anticipated_within_week_yes) + sum(critical_staffing_shortage_anticipated_within_week_no)) / total) %>%
arrange (desc(date)) %>%
filter (date > as.Date("2020-07-31"))
hospital6 <- hospital5 %>%
arrange(state, date)
hospital5a <- hospital5 %>%
arrange (state, date) %>%
group_by (state) %>%
mutate (#days_low_vax = RcppRoll::roll_sum(dplyr::lag(low_vax),14, fill=NA, align="right"),
#days_low_st_vax = RcppRoll::roll_sum(dplyr::lag(low_st_vax),14, fill=NA, align="right"),
x7_day_rolling_reporting = zoo::rollmean(tot_report, k = 7, fill = NA, align = "right"),
x7_day_rolling_avg_pct_hospitals_anticipating_shortage = zoo::rollmean(pct_yes, k = 7, fill = NA, align = "right")* 100,
x7_day_rolling_avg_pct_hospitals_reporting = zoo::rollmean(pct_reporting, k = 7, fill = NA, align = "right")* 100) %>%
rename (pct_hospitals_anticipating_shortage = pct_yes,
pct_hospitals_reporting = pct_reporting) %>%
arrange (state, desc(date)) #rearrange, most recent first
today <- hospital5 %>%
filter (date == (Sys.Date()-5)) %>%
arrange (desc(pct_yes)) %>%
print()
today %>%
filter (pct_yes >= .25)
#Count states with extreme hospital needs (>25%)
hospital5 %>%
group_by (date) %>%
count (over25 = pct_yes >= .25) %>%
mutate (pct = n /sum(n) * 100) %>%
filter (over25=="TRUE") %>%
ggplot (aes(x=date, y=n)) +
geom_line() +
labs(x="Date",
y="# of states",
title="Count of 54 states with over 25% of hospitals anticipating critical\nstaffing shortages within a week",
#subtitle="",
#fill="95% CI for trendline",
caption="Source: U.S. Department of Health & Human Services") +
scale_x_date(#limits = c(as.Date("2006-12-31"), as.Date("2014-09-30")),
breaks = seq(as.Date("2020-08-01"), as.Date("2022-12-01"), "month"),
date_labels = "%b %Y") +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
scale_y_continuous(limits = c(0,35),
breaks = seq(0, 100, by = 5),
#labels = paste0(seq(0, 100, by = 5), "%")
) +
geom_smooth()
stop ("FINISHED")
View(hospital5)
library(tidyverse)
library(readxl)
library(janitor)
library(lubridate)
library(beepr)
library(rvest)
library(jsonlite)
api_pull <- fromJSON("https://www.treasurydirect.gov/TA_WS/securities/search?type=Bill&format=json")
#api_pull <- fromJSON("https://www.treasurydirect.gov/TA_WS/securities/search?securityTerm=4-Week&format=json")
api_pull %>%
count (securityTerm) %>%
arrange (desc(n)) %>%
filter (str_detect(securityTerm, "Week"))
x4weekbills <- api_pull %>%
clean_names() %>%
select (cusip, security_type, security_term, auction_date, issue_date, maturity_date, price_per100) %>%
mutate (across(c(4:6), ~as.Date(format(ymd_hms(.x), "%Y-%m-%d"))),
price_per100=as.numeric(price_per100)) %>%
filter (str_detect(security_term, "Week")) %>%
mutate (weeks = as.numeric(word(str_replace(security_term, "-", " "), 1))) %>%
mutate (int=100-price_per100,
daily_int=int/(weeks*7),
#apy=int/price_per_100,
yearly_int=daily_int*365,
apy=round(yearly_int/price_per100*100, 3),
term=as.numeric(str_extract(security_term, "[0-9]*"))
) %>%
arrange (term, desc(auction_date))
x4weekbills %>%
filter (issue_date>=as.Date("2021-01-01")) %>%
#filter (security_term=="4-Week") %>%
ggplot (aes(y=apy, x=issue_date, color=security_term)) +
geom_line() +
labs(x="Issue date",
y="APY",
title="APY of 4-week Treasury bills") +
##subtitle="Comparing rural vs urban and LMI (low-to-middle-income) status",
#fill="95% CI for trendline",
#caption="Source: U.S. Small Business Administration\nNote: Larger numbers show pct. pt. difference between LMI & non-LMI.") +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
scale_x_date(#limits = c(as.Date(Sys.Date()-years(2)-months(1)), as.Date(Sys.Date()+days(14))),
date_breaks = "1 month", date_labels = "%b %y"
#date_breaks = "2 months", date_labels = "%b %y"
#date_breaks = "1 year", date_labels = "%y"
) +
scale_y_continuous (breaks=seq(0,6, 1),
minor_breaks=seq(0,6, 0.5))
View(x4weekbills)
library(tidyverse)
library(jsonlite)
cincy <- data.table::fread("https://data.cincinnati-oh.gov/api/views/k59e-2pvf/rows.csv?accessType=DOWNLOAD")
conroy <- cincy %>%
filter (str_detect(ADDRESS_X, "5XX CONROY ST"))
View(conroy)
library(geosphere)
library(tidyverse)
library(lubridate)
cincy1 <- cincy %>%
mutate(dist = distHaversine(cbind(myLong, myLat), cbind(LONGITUDE_X, LATITUDE_X)),
date = mdy_hms(DATE_REPORTED),
year = year (date),
content = paste0("<i>", DATE_REPORTED, "</i><br>", ADDRESS_X, "<br>", OFFENSE))
myLat <- conroy %>% summarize (median (LATITUDE_X)) %>% pull()
myLong <- conroy %>% summarize (median (LONGITUDE_X)) %>% pull()
cincy1 <- cincy %>%
mutate(dist = distHaversine(cbind(myLong, myLat), cbind(LONGITUDE_X, LATITUDE_X)),
date = mdy_hms(DATE_REPORTED),
year = year (date),
content = paste0("<i>", DATE_REPORTED, "</i><br>", ADDRESS_X, "<br>", OFFENSE))
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date < Sys.Date()-years(2))
# Create a leaflet map
library(leaflet)
m <- leaflet(cincy2) %>%
addTiles()  %>% # Add map tiles as the base layer
addCircleMarkers(
lat = ~LATITUDE_X,
lng = ~LONGITUDE_X,
popup = ~content,
fillColor = "goldenrod",
fillOpacity = 1,
stroke = F
)
# Display the map
m
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date < Sys.Date()-months(2))
# Create a leaflet map
library(leaflet)
m <- leaflet(cincy2) %>%
addTiles()  %>% # Add map tiles as the base layer
addCircleMarkers(
lat = ~LATITUDE_X,
lng = ~LONGITUDE_X,
popup = ~content,
fillColor = "goldenrod",
fillOpacity = 1,
stroke = F
)
# Display the map
m
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date < Sys.Date()-month(2))
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date < Sys.Date()-years(2))
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date < (Sys.Date()-years(2)))
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date < (Sys.Date()-days(60)))
Sys.Date()-days(60)
View(cincy2)
type(Sys.Date()-days(60))
class(Sys.Date()-days(60))
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date > (Sys.Date()-days(60)))
View(cincy2)
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date > (Sys.Date()-years(2)))
# Create a leaflet map
library(leaflet)
m <- leaflet(cincy2) %>%
addTiles()  %>% # Add map tiles as the base layer
addCircleMarkers(
lat = ~LATITUDE_X,
lng = ~LONGITUDE_X,
popup = ~content,
fillColor = "goldenrod",
fillOpacity = 1,
stroke = F
)
# Display the map
m
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date > (Sys.Date()-years(2)))
View(cincy2)
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date > (Sys.Date()-years(2))) %>%
mutate (street = str_remove(ADDRESS_X, "6[:digit:]X+ "))
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date > (Sys.Date()-years(2))) %>%
mutate (street = str_remove(ADDRESS_X, "^[:digit:]+X+ "))
cincy1 <- cincy %>%
mutate(dist = distHaversine(cbind(myLong, myLat), cbind(LONGITUDE_X, LATITUDE_X)),
date = mdy_hms(DATE_REPORTED),
year = year (date),
content = paste0("<i>", DATE_REPORTED, "</i><br>", ADDRESS_X, "<br>", OFFENSE),
street = str_remove(ADDRESS_X, "^[:digit:]+X+ "))
cincy2 <- cincy1 %>%
filter (dist < 250) %>%
filter (date > (Sys.Date()-years(2)))
View(cincy2)
cincy2 %>%
count (street)
cincy2 %>%
count (street, sort=T)
cincy2 <- cincy1 %>%
filter (dist < 500) %>%
filter (date > (Sys.Date()-years(2)))
cincy2 %>%
count (street, sort=T)
View(conroy)
